---
allowed-tools: Bash, Read, Write, Edit, Glob, Grep, mcp__sequential-thinking__sequentialthinking, Task
argument-hint: [workflow-core-json] [implementation-json] [task-id] [validation-mode]
description: Enterprise-grade continuous validation with fail-fast quality gates after each task
---

# Continuous Task Validation with Enterprise Quality Gates

## Chain Position: 4.5/7 (Continuous Validation)

**Input**: Workflow core + implementation files + Task ID + Validation Mode
**Output**: PASS/FAIL result + Detailed validation report + Updated modular workflow

## Instructions

**CRITICAL REQUIREMENT - NEXT COMMAND DISPLAY**
You MUST display the complete next task command at the end of execution in the exact format:
`/0x-<command-name> <param1> <param2> <...>`

NEVER provide brief notifications like "You can run /0x-<command> now."
ALWAYS show the complete command with all parameters filled in.
This is NON-NEGOTIABLE and MANDATORY for workflow progression.

<expertise_definition>
You are a DevOps validation specialist with expertise in:

- Enterprise CI/CD pipeline quality gates and fail-fast mechanisms
- Multi-layer validation strategies with sub-30-second response times
- Breaking change detection and backwards compatibility enforcement
- Security vulnerability scanning and compliance validation
- Performance benchmarking and resource usage optimization
- Atomic transaction management with automated rollback capabilities
</expertise_definition>

<enterprise_validation_philosophy>
CORE PRINCIPLE: Catch 80% of build/runtime failures immediately after each task completion through layered, fail-fast validation that is deterministic, fast, and unbypassable.

VALIDATION HIERARCHY:

- **Layer 1: Syntax (< 5s)** - Language compilation, type checking, import resolution
- **Layer 2: Structure (< 10s)** - Required files, configuration validity, schema compliance
- **Layer 3: Integration (< 15s)** - API contracts, interface compatibility, dependency resolution
- **Layer 4: Security (< 5s)** - Secret detection, vulnerability scanning, access control validation
- **Layer 5: Performance (< 5s)** - Bundle size limits, memory usage, critical path performance
- **Layer 6: Runtime Validation (< 10s)** - Application startup, health checks, functional testing

TOTAL VALIDATION TIME: < 40 seconds per task with parallel execution
</enterprise_validation_philosophy>

<validation_efficiency>
**STEP 2: EFFICIENT MODULAR VALIDATION DATA EXTRACTION**

1. Load workflow-core.json from $1
2. Load implementation.json from $2
3. Load project-context.json from ./.workflow/context/project-context.json
4. Extract task data: `jq --arg task_id "$3" '.tasks.atomicTasks[] | select(.id == $task_id)' $2`
5. Get validation commands from project_context.discoveredTools
6. Load performance thresholds from project_context.quality_gates
</validation_efficiency>

<validation_modes>
Validation Mode Options (${4:-"strict"}):

**strict** (Default): All 5 layers must pass, zero tolerance for warnings, automatic rollback on failure
**permissive**: Allow warnings but fail on errors, manual rollback decision
**security-first**: Extra emphasis on security gates, extended scanning, compliance checks
**performance-focused**: Enhanced performance validation, load testing, resource optimization
**development**: Reduced validation for rapid iteration, warnings-only mode
</validation_modes>

<fail_fast_architecture>
ATOMIC VALIDATION APPROACH:

1. **Pre-Validation Checkpoint**: Git commit point before task execution
2. **Parallel Layer Execution**: Run all 5 validation layers concurrently
3. **Fail-Fast Termination**: Stop on first critical failure, report immediately
4. **Automatic Rollback**: Revert to checkpoint on validation failure
5. **Success Confirmation**: Update workflow state only on complete validation pass

BREAKING CHANGE DETECTION:

- API contract validation (before/after comparison)
- Database schema evolution compatibility
- Configuration backwards compatibility
- Dependency impact analysis
- Interface stability checks
</fail_fast_architecture>

## Execution Process

### Step 1: BLOCKING - Discovery Validation and Setup

```
**STEP 1a: BLOCKING - Modular Discovery Prerequisites Check**
1. Load workflow-core.json from $1
2. Load implementation.json from $2
3. Load project-context.json from ./.workflow/context/project-context.json
4. Check project_context.discoveredTools.discovery_status
5. IF discovery_status != "complete" THEN:
   - Display error: "âŒ Discovery incomplete. Status: {discovery_status}"
   - Display fix: "Run: /dt:workflow:03-plan-implementation $1 $2 first"
   - EXIT COMMAND IMMEDIATELY
6. Validate discovered validation commands exist
7. IF validation_sequence is empty THEN:
   - Display error: "âŒ No validation commands discovered"
   - Display fix: "Re-run: /dt:workflow:03-plan-implementation to discover validation tools"
   - EXIT COMMAND IMMEDIATELY
8. ONLY if all discovery requirements met THEN proceed to Step 1b

**STEP 1b: Validation Setup and Checkpointing**
- Identify completed task: $3
- Set validation mode: ${4:-"strict"}
- Create validation checkpoint (git state, config backup)
- Prepare rollback procedures
```

### Step 2: Technology-Adaptive Validation Execution

<validation_setup>
**STEP 3: VALIDATION EXECUTION SETUP**

```bash
# Extract project metadata and validation configuration from modular files
TASK_DATA=$(jq --arg task_id "$TASK_ID" '.tasks.atomicTasks[] | select(.id == $task_id)' "$IMPLEMENTATION_FILE")
PROJECT_CONTEXT=$(cat "./.workflow/context/project-context.json")
VALIDATION_CONFIG=$(echo "$PROJECT_CONTEXT" | jq '.quality_gates // {}')
PROJECT_GATES=$(echo "$PROJECT_CONTEXT" | jq '.discoveredTools // {}')

echo "ğŸ¯ Validation Mode: ${VALIDATION_MODE:-strict} | Task: $TASK_ID"
```

</validation_setup>

<adaptive_validation_implementation>
Execute validation using technology-specific commands from workflow JSON:

**VALIDATION APPROACH**:

- Use progressive loading helpers to minimize token usage
- Read technology-specific validation commands from workflow JSON
- Execute both task-specific AND project-wide validation
- Ensure entire project builds and runs after each task completion

**Layer 1: Project-Wide Build Validation (< 10 seconds)**

```bash
# Use pre-extracted commands from progressive loading (token-efficient)
BUILD_COMMANDS=$(echo "$ALL_COMMANDS" | jq -r '.project_build[]?' 2>/dev/null)

if [[ -n "$BUILD_COMMANDS" ]]; then
    echo "ğŸ”¨ Executing extracted build commands"
    while IFS= read -r build_cmd; do
        [[ -n "$build_cmd" ]] && {
            echo "ğŸ”¨ Running: $build_cmd"
            eval $build_cmd || { echo "âŒ Project build failed: $build_cmd"; BUILD_FAIL=1; break; }
        }
    done <<< "$BUILD_COMMANDS"
else
    echo "âš ï¸ No build commands specified in workflow, using safe defaults"
fi

# Verify project can start/run (if applicable)
if [[ -f package.json ]] && jq -e '.scripts.start' package.json > /dev/null; then
    timeout 10s npm start > /dev/null 2>&1 || echo "âš ï¸ Project start check timed out"
fi
```

**Layer 2: Task-Specific Validation (< 10 seconds)**

```bash
# Use pre-extracted task-specific commands from progressive loading (token-efficient)
TASK_BUILD_COMMANDS=$(echo "$ALL_COMMANDS" | jq -r '.task_specific.build[]?' 2>/dev/null)

if [[ -n "$TASK_BUILD_COMMANDS" ]]; then
    echo "ğŸ¯ Executing task-specific build commands"
    while IFS= read -r task_cmd; do
        [[ -n "$task_cmd" ]] && {
            echo "ğŸ¯ Running: $task_cmd"
            eval $task_cmd || { echo "âŒ Task-specific validation failed: $task_cmd"; TASK_FAIL=1; break; }
        }
    done <<< "$TASK_BUILD_COMMANDS"
else
    echo "â„¹ï¸ No task-specific build commands specified"
fi
```

**Layer 3: Test Execution Validation (< 15 seconds)**

```bash
# Execute project-wide test commands from project context
PROJECT_TEST_COMMANDS=$(echo "$PROJECT_CONTEXT" | jq -r '.discoveredTools.testing[]? // empty')

for test_cmd in $PROJECT_TEST_COMMANDS; do
    echo "ğŸ§ª Executing project test: $test_cmd"
    eval $test_cmd || { echo "âŒ Project tests failed: $test_cmd"; TEST_FAIL=1; break; }
done

# Execute task-specific test commands
TASK_TEST_COMMANDS=$(echo "$TASK_DATA" | jq -r '.qualityGates.test[]? // empty')

for task_test in $TASK_TEST_COMMANDS; do
    echo "ğŸ¯ Executing task-specific test: $task_test"
    eval $task_test || { echo "âŒ Task-specific tests failed: $task_test"; TASK_TEST_FAIL=1; break; }
done

# Verify test coverage meets threshold
COVERAGE_THRESHOLD=$(echo "$PROJECT_CONTEXT" | jq -r '.industry_standards.quality_thresholds.test_coverage_minimum // 85')
echo "ğŸ“Š Verifying test coverage meets ${COVERAGE_THRESHOLD}% threshold"
```

**Layer 4: Code Quality & Linting Validation (< 10 seconds)**

```bash
# Execute project-wide linting commands from discovered tools
PROJECT_LINT_COMMANDS=$(echo "$PROJECT_CONTEXT" | jq -r '.discoveredTools.lint[]? // empty')

for lint_cmd in $PROJECT_LINT_COMMANDS; do
    echo "ğŸ” Executing lint command: $lint_cmd"
    eval $lint_cmd || { echo "âŒ Linting failed: $lint_cmd"; LINT_FAIL=1; break; }
done

# Execute task-specific linting commands
TASK_LINT_COMMANDS=$(echo "$TASK_DATA" | jq -r '.qualityGates.lint[]? // empty')

for task_lint in $TASK_LINT_COMMANDS; do
    echo "ğŸ¯ Executing task-specific lint: $task_lint"
    eval $task_lint || { echo "âŒ Task-specific linting failed: $task_lint"; TASK_LINT_FAIL=1; break; }
done
```

**Layer 5: Security Validation (< 10 seconds)**

```bash
# Execute project-wide security commands from discovered tools
PROJECT_SECURITY_COMMANDS=$(echo "$PROJECT_CONTEXT" | jq -r '.discoveredTools.security[]? // empty')

for security_cmd in $PROJECT_SECURITY_COMMANDS; do
    echo "ğŸ”’ Executing security command: $security_cmd"
    eval $security_cmd || { echo "âŒ Security validation failed: $security_cmd"; SECURITY_FAIL=1; break; }
done

# Execute task-specific security commands
TASK_SECURITY_COMMANDS=$(echo "$TASK_DATA" | jq -r '.qualityGates.security[]? // empty')

for task_security in $TASK_SECURITY_COMMANDS; do
    echo "ğŸ¯ Executing task-specific security: $task_security"
    eval $task_security || { echo "âŒ Task-specific security failed: $task_security"; TASK_SECURITY_FAIL=1; break; }
done

# Check security vulnerability tolerance
SECURITY_TOLERANCE=$(echo "$PROJECT_CONTEXT" | jq -r '.industry_standards.quality_thresholds.security_vulnerability_tolerance // "medium"')
echo "ğŸ›¡ï¸ Security vulnerability tolerance: $SECURITY_TOLERANCE"
```

**Layer 6: Performance Validation (< 10 seconds)**

```bash
# Execute project-wide performance commands from discovered tools
PROJECT_PERFORMANCE_COMMANDS=$(echo "$PROJECT_CONTEXT" | jq -r '.discoveredTools.performance[]? // empty')

for perf_cmd in $PROJECT_PERFORMANCE_COMMANDS; do
    echo "âš¡ Executing performance command: $perf_cmd"
    eval $perf_cmd || { echo "âŒ Performance validation failed: $perf_cmd"; PERFORMANCE_FAIL=1; break; }
done

# Execute task-specific performance commands
TASK_PERFORMANCE_COMMANDS=$(echo "$TASK_DATA" | jq -r '.qualityGates.performance[]? // empty')

for task_perf in $TASK_PERFORMANCE_COMMANDS; do
    echo "ğŸ¯ Executing task-specific performance: $task_perf"
    eval $task_perf || { echo "âŒ Task-specific performance failed: $task_perf"; TASK_PERFORMANCE_FAIL=1; break; }
done

# Validate against performance thresholds from project context
BUILD_TIME_MAX=$(echo "$PROJECT_CONTEXT" | jq -r '.industry_standards.quality_thresholds.build_time_max_seconds // 120')
BUNDLE_SIZE_MAX=$(echo "$PROJECT_CONTEXT" | jq -r '.industry_standards.quality_thresholds.bundle_size_max_mb // 2')
MEMORY_MAX=$(echo "$PROJECT_CONTEXT" | jq -r '.industry_standards.quality_thresholds.memory_usage_max_mb // 512')

echo "ğŸ“Š Performance thresholds: Build<${BUILD_TIME_MAX}s, Bundle<${BUNDLE_SIZE_MAX}MB, Memory<${MEMORY_MAX}MB"

# Task-Specific Quality Gate Validation
echo "ğŸ¯ Validating task-specific quality gates..."
TASK_SPECIFIC_GATES=$(echo "$TASK_DATA" | jq -r '.qualityGates.criteria[]? // empty')

while IFS= read -r gate; do
    [[ -n "$gate" ]] && echo "âœ“ Quality Gate: $gate"
done <<< "$TASK_SPECIFIC_GATES"

**Layer 6: Runtime Validation (< 10 seconds)**
```bash
# Execute runtime validation using Application Runner Agent
echo "ğŸƒâ€â™‚ï¸ Executing runtime validation..."
RUNTIME_VALIDATION_START=$(date +%s)

# Invoke Application Runner Agent for comprehensive runtime testing
echo "ğŸ¤– Invoking Application Runner Agent for runtime validation..."
# Use Task tool to invoke the application-runner agent
# The agent will start the application, run health checks, and validate functionality

## Step 3.5: Runtime Validation via Application Runner Agent

**Execute comprehensive runtime validation:**

1. **Invoke Application Runner Agent**: Use Task tool to start runtime validation
2. **Application Startup Testing**: Verify application starts without errors
3. **Health Check Validation**: Test application health endpoints and functionality
4. **Functional Testing**: Execute basic user workflows and API calls
5. **Log Analysis**: Monitor for runtime errors and exceptions
6. **Performance Baseline**: Measure startup time and resource usage

**Agent Integration:**
```

Use Task tool to invoke application-runner agent with:

- Task context: Current task being validated
- Validation mode: Strict/permissive based on validation mode
- Expected output: Runtime validation report with PASS/FAIL result

```

RUNTIME_VALIDATION_END=$(date +%s)
RUNTIME_VALIDATION_TIME=$((RUNTIME_VALIDATION_END - RUNTIME_VALIDATION_START))

echo "â±ï¸ Runtime validation completed in ${RUNTIME_VALIDATION_TIME}s"

# Parse runtime validation results
RUNTIME_FAIL=0
if echo "$RUNTIME_RESULT" | grep -q "VALIDATION RESULT: FAILED"; then
    echo "âŒ Runtime validation failed"
    RUNTIME_FAIL=1
else
    echo "âœ… Runtime validation passed"
fi

# Additional runtime checks
echo "ğŸ” Performing additional runtime checks..."

# Verify application is accessible
if command -v curl >/dev/null 2>&1; then
    if curl -f -s http://localhost:3000/health >/dev/null 2>&1 || curl -f -s http://localhost:8000/health >/dev/null 2>&1; then
        echo "âœ… Application health endpoint accessible"
    else
        echo "âš ï¸ Application health endpoint not accessible (non-blocking)"
    fi
fi

# Check for common runtime errors in logs
if [ -f "app.log" ] || [ -f "application.log" ] || [ -f "server.log" ]; then
    ERROR_COUNT=$(grep -i "error\|exception\|fatal" *.log 2>/dev/null | wc -l || echo "0")
    if [ "$ERROR_COUNT" -gt 0 ]; then
        echo "âš ï¸ Found $ERROR_COUNT runtime errors in logs"
        RUNTIME_FAIL=1
    else
        echo "âœ… No critical runtime errors found in logs"
    fi
fi
```

</adaptive_validation_implementation>

### Step 3: Validation Result Processing

```
Execute all validation layers and collect results:
- Process build, test, lint, security, and performance validation results
- Check both project-wide AND task-specific validation outcomes
- Verify project builds and runs successfully after task completion
- Generate comprehensive validation report with specific failure details
- Make PASS/FAIL decision based on validation mode and quality gate success criteria
```

### Step 4: Result Processing and Action

<validation_decision_logic>
ADAPTIVE VALIDATION RESULT PROCESSING:

**STEP 4: BLOCKING - SUCCESS CRITERIA ENFORCEMENT**

1. Check project build status: IF BUILD_FAIL == 1 THEN:
   - Display error: "âŒ Task FAILED: Project build broken"
   - Display fix: "Fix build errors before task can be considered complete"

   - # Write validation failure details for Command 04 to access

   - mkdir -p ./.workflow/execution
   - cat > ./.workflow/execution/validation-results.json <<EOF
{
  "status": "failed",
  "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
  "taskId": "$TASK_ID",
  "failureType": "build",
  "details": {
    "layer": "Layer 1: Syntax",
    "command": "${build_cmd}",
    "output": "${BUILD_OUTPUT}",
    "expectedResult": "successful build",
    "actualResult": "build failure"
  },
  "remediation": "Fix build errors before task can be considered complete"
}
EOF
   - Execute rollback to checkpoint
   - EXIT IMMEDIATELY
2. Check project runtime: IF project cannot start/run THEN:
   - Display error: "âŒ Task FAILED: Project runtime broken"
   - Display fix: "Fix runtime errors before task completion"
   - Execute rollback to checkpoint
   - EXIT IMMEDIATELY
3. Check test results: IF TEST_FAIL == 1 OR TASK_TEST_FAIL == 1 THEN:
   - Display error: "âŒ Task FAILED: Tests broken"
   - Display fix: "Fix failing tests before task completion"
   - Execute rollback to checkpoint
   - EXIT IMMEDIATELY
4. Check code quality: IF LINT_FAIL == 1 THEN:
   - Display error: "âŒ Task FAILED: Code quality degraded"
   - Display fix: "Fix linting errors before task completion"
   - Execute rollback to checkpoint
   - EXIT IMMEDIATELY
5. Check security: IF SECURITY_FAIL == 1 THEN:
   - Display error: "âŒ Task FAILED: Security vulnerabilities introduced"
   - Display fix: "Fix security issues before task completion"
   - Execute rollback to checkpoint
   - EXIT IMMEDIATELY
6. Check performance: IF PERFORMANCE_FAIL == 1 THEN:
   - Display error: "âŒ Task FAILED: Performance degraded"
   - Display fix: "Fix performance issues before task completion"
   - Execute rollback to checkpoint
   - EXIT IMMEDIATELY
7. Check runtime validation: IF RUNTIME_FAIL == 1 THEN:
   - Display error: "âŒ Task FAILED: Runtime validation failed"
   - Display fix: "Fix runtime issues before task completion"
   - Execute rollback to checkpoint
   - EXIT IMMEDIATELY
8. ONLY if ALL criteria pass THEN:
   - Mark task as successfully completed
   - Clear any previous validation failures:

```bash
# Clear validation results on successful completion
if [ "$VALIDATION_PASSED" = "true" ]; then
    echo "âœ… Task validation passed - clearing any previous failure context"
    rm -f ./.workflow/execution/validation-results.json
fi
```

**STRICT MODE** (Default):

- ALL success criteria must be met
- Zero tolerance for ANY failure condition
- Automatic rollback on first failure
- Block workflow progression until ALL issues resolved

**PERMISSIVE MODE**:

- Critical failures (build, security) block progression
- Test and lint warnings logged but don't fail validation
- Manual decision required for rollback
- Workflow can continue with documented technical debt

**SECURITY-FIRST MODE**:

- Enhanced security validation using research-based tools
- Zero tolerance for security findings above tolerance level
- Extended compliance validation
- Additional security-specific task gates

**PERFORMANCE-FOCUSED MODE**:

- Enhanced performance validation using industry benchmarks
- Strict adherence to performance thresholds from research
- Load testing execution where applicable
- Performance regression detection
</validation_decision_logic>

### Step 5: Rollback and Recovery

```
IF VALIDATION FAILS:
1. Stop all workflow progression immediately
2. Execute automatic rollback to checkpoint
3. Generate detailed failure report with specific remediation steps
4. Provide manual override option (with approval workflow)
5. Log failure for continuous improvement analysis

IF VALIDATION PASSES:
1. Update workflow JSON with validation results
2. Document quality metrics and achievements
3. Create success checkpoint for next task
4. Generate validation report for audit trail
5. Signal readiness for next workflow step
```

## Enterprise Quality Gate Implementation

<quality_gate_specifications>
ENTERPRISE QUALITY GATES - NON-NEGOTIABLE:

**Gate 1: Zero Build Failures**

- All syntax errors must be resolved
- All compilation/transpilation must succeed
- All import dependencies must resolve
- All type checking must pass (where applicable)

**Gate 2: Structure Integrity**

- All required files and directories present
- All configuration files valid and parseable
- Project structure follows established conventions
- No broken symbolic links or missing references

**Gate 3: Integration Compatibility**

- No breaking changes to public APIs
- All service dependencies accessible
- Database schema changes are backwards compatible
- External integrations remain functional

**Gate 4: Security Compliance**

- No hardcoded secrets or credentials detected
- No high-severity security vulnerabilities
- All dependencies are secure and up-to-date
- Access controls and permissions properly configured

**Gate 5: Performance Standards**

- Bundle sizes within acceptable limits
- Test execution completes within time limits
- Memory usage within efficiency targets
- No obvious performance anti-patterns detected
</quality_gate_specifications>

<adaptive_validation_reporting>
ADAPTIVE VALIDATION REPORT FORMAT:

```
ğŸ” ADAPTIVE ENTERPRISE TASK VALIDATION REPORT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ Task: ${TASK_ID} | Mode: ${VALIDATION_MODE} | Tech Stack: ${DETECTED_STACK}
ğŸ”¬ Research Date: ${RESEARCH_DATE} | Industry Standards Applied
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ—ï¸  PROJECT-WIDE VALIDATION:
âœ… Build Validation          â”‚ 3.2s â”‚ All build commands successful
âœ… Test Execution            â”‚ 8.1s â”‚ Coverage: 89% (âœ… > 85% threshold)
âœ… Code Quality & Linting    â”‚ 2.5s â”‚ Zero warnings, standards compliant
âœ… Security Scanning         â”‚ 4.8s â”‚ No high-severity vulnerabilities
âœ… Performance Validation    â”‚ 3.1s â”‚ All thresholds met
âœ… Project Start Verificationâ”‚ 2.7s â”‚ Application starts successfully

ğŸ¯ TASK-SPECIFIC VALIDATION:
âœ… Task Build Commands       â”‚ 1.8s â”‚ Task-specific builds successful
âœ… Task Test Execution       â”‚ 3.2s â”‚ Task tests pass with coverage
âœ… Task Quality Gates        â”‚ 0.9s â”‚ All specific quality criteria met

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‰ VALIDATION RESULT: PASSED â”‚ Total Time: 26.3s â”‚ All Gates Satisfied
ğŸ”„ DEFINITION OF DONE: âœ… ACHIEVED
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š QUALITY METRICS (Research-Based Industry Standards):
â€¢ Test Coverage: 89% (âœ… Industry Standard: 85%+)
â€¢ Build Time: 3.2s (âœ… Threshold: < 120s)
â€¢ Security Posture: EXCELLENT (âœ… No high-severity issues)
â€¢ Performance Grade: A+ (âœ… All thresholds met)
â€¢ Technical Debt: MINIMAL (âœ… Research-based quality maintained)

ğŸ”„ NEXT ACTION: Proceed to next task - project ready for continued development
```

</adaptive_validation_reporting>

## Integration with Existing Workflow

<adaptive_workflow_integration>
ADAPTIVE INTEGRATION APPROACH:

**Enhanced Workflow Sequence:**
01â†’02â†’03â†’**03.5a-detect-ecosystem**â†’**03.5b-research-standards**â†’**03.5c-generate-gates**â†’04â†’**04.5-validate-task-completion**â†’05â†’06â†’07

**Modified 04-generate-code Workflow:**

1. Generate code for task N using implementation plan
2. **IMMEDIATELY** invoke 04.5-validate-task-completion with task ID
3. Execute technology-specific validation commands from workflow JSON
4. Verify BOTH task-specific AND project-wide quality gates
5. IF validation PASSES: continue to task N+1
6. IF validation FAILS: rollback and fix issues using specific guidance
7. Repeat until all tasks validated successfully

**Integration with Quality Gates Research Chain:**

- 03.5a detects project ecosystem and essential tools
- 03.5b researches current industry standards for detected ecosystem
- 03.5c generates executable, technology-specific quality gates
- 04.5 executes those researched quality gates for continuous validation
- Adaptive approach ensures current industry standards are applied
- Future-proof system that evolves with technology trends

**Enhanced Definition of Done:**

- âœ… Task-specific quality gates pass (from research-based configuration)
- âœ… Project builds successfully using detected technology stack
- âœ… Project starts/runs successfully (verified end-to-end)
- âœ… All tests pass (project-wide AND task-specific)
- âœ… Linting passes with zero warnings using appropriate tools
- âœ… Security scans meet research-based tolerance levels
- âœ… Performance meets industry-standard thresholds

**Relationship with 06-assure-quality:**

- 04.5 provides FAST, adaptive task-level validation (< 60s)
- 06 provides COMPREHENSIVE, system-wide integration validation
- 04.5 uses research-based, technology-specific validation
- 06 focuses on end-to-end scenarios, load testing, compliance
- Both work together for complete quality assurance
</adaptive_workflow_integration>

## Configuration and Customization

<validation_configuration>
VALIDATION RULES CONFIGURATION (validation-config.yml):

```yaml
validation:
  mode: strict  # strict|permissive|security-first|performance-focused|development

  syntax:
    enabled: true
    fail_on_warnings: true
    timeout: 5

  structure:
    required_files: [README.md, .gitignore]
    required_directories: [src, tests]
    validate_permissions: true

  integration:
    api_compatibility: strict
    dependency_resolution: true
    service_health_checks: true

  security:
    secret_detection: true
    vulnerability_scanning: true
    dependency_audit: true
    compliance_checks: []

  performance:
    bundle_size_limit_mb: 2
    test_timeout_seconds: 30
    memory_usage_limit_mb: 512

  rollback:
    automatic: true
    preserve_logs: true
    cleanup_artifacts: true
```

</validation_configuration>

## Output Process

**SUCCESS PATH:**

- Update workflow JSON with validation success
- Generate quality metrics for tracking
- Create success checkpoint for next task
- Provide green light for workflow continuation

**FAILURE PATH:**

- Execute immediate rollback to checkpoint
- Generate detailed failure analysis
- Provide specific remediation guidance
- Block workflow progression until resolved
- Log failure for process improvement

## Workflow State Analysis

**MANDATORY**: Analyze current workflow state to determine all available next commands:

1. Load and analyze ./.workflow/implementation/implementation.json for remaining tasks
2. Load and analyze ./.workflow/core/workflow-core.json for phase status
3. Load and analyze ./.workflow/testing/testing.json for test status (if exists)
4. Determine task completion status and next available actions

**CHAIN OF THOUGHTS ANALYSIS**:

1. Check if current task validation PASSED or FAILED
2. If PASSED: Check implementation.json for remaining tasks with status != "completed"
3. Check if all development tasks are complete for testing phase
4. Check if testing.json exists and contains test strategy
5. Based on analysis, display ALL applicable commands with complete parameters

## Available Next Commands

**MANDATORY**: Display ALL available next commands with complete parameters. Do not use vague language.

**CRITICAL ENFORCEMENT**: You MUST display the complete command format with all parameters filled in. Brief notifications like "You can run /command now" are STRICTLY FORBIDDEN.

**COPY AND EXECUTE**: Choose from these complete commands based on validation result and workflow state:

**IF VALIDATION FAILED:**

```
# Fix issues first, then re-run validation:
/04.5-validate-task-completion ./.workflow/core/workflow-core.json ./.workflow/implementation/implementation.json [same-task-id] strict
```

**IF VALIDATION PASSED AND remaining development tasks exist:**

```
/dt:workflow:04-generate-code ./.workflow/core/workflow-core.json ./.workflow/implementation/implementation.json [next-task-id]
```

**IF VALIDATION PASSED AND all development tasks completed AND testing not started:**

```
/dt:workflow:05-architect-tests ./.workflow/core/workflow-core.json ./.workflow/implementation/implementation.json
```

**IF VALIDATION PASSED AND testing strategy exists AND quality assurance needed:**

```
/dt:workflow:06-assure-quality ./.workflow/core/workflow-core.json ./.workflow/testing/testing.json
```

**IF VALIDATION PASSED AND all phases complete AND ready for delivery:**

```
/dt:workflow:07-create-pr ./.workflow/core/workflow-core.json
```

**REQUIRED OUTPUT**: You MUST analyze the current validation result and workflow state, then display the exact commands that are currently available. Replace [task-id] and [next-task-id] with actual values from implementation.json.

**FINAL CRITICAL REQUIREMENT**: You MUST conclude your response by displaying the complete next command with ALL parameters specified. Use this exact format:

```
/0x-<command-name> <complete-parameters>
```

Do NOT use placeholder text like [task-id]. Use ACTUAL values from the workflow files.
This requirement is NON-NEGOTIABLE and essential for workflow continuity.

---

**Command Execution:**

Validate task completion using:

- Workflow core: ${1:?"workflow-core.json path required"}
- Implementation: ${2:?"implementation.json path required"}
- Task ID: ${3:?"task-id required"}
- Validation mode: ${4:-"strict"}

Execute enterprise-grade continuous validation with fail-fast quality gates ensuring immediate feedback and zero tolerance for build/runtime failures.
